# -*- coding: utf-8 -*-
"""ProyectoV01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KEGReTraJ2tgyTixej4cP9ImYowtkJZq
"""

#@title Datos | Funciones de entrenamiento y Evaluacion de los Modelos.

import time
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
import pandas as pd
import psutil

# Cargar el dataset
def load_and_preprocess_data(file_path):
    df = pd.read_csv(file_path)
    df = df.dropna(subset=['fetal_health'])
    X = df.drop('fetal_health', axis=1)
    y = df['fetal_health']

    imputer = SimpleImputer(strategy='mean')
    X = imputer.fit_transform(X)

    return train_test_split(X, y, test_size=0.2, random_state=42)

# Función general para entrenar y evaluar modelos
def train_and_evaluate(model, model_name, X_train, X_test, y_train, y_test):
    start_time = time.time()
    process = psutil.Process()

    mem_before = process.memory_info().rss / 1024 / 1024

    print(f"Entrenando {model_name}...")
    model.fit(X_train, y_train)

    mem_after = process.memory_info().rss / 1024 / 1024
    train_time = time.time() - start_time

    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    results = {
        'model': model_name,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'train_time': train_time,
        'memory_usage': mem_after - mem_before
    }

    return results

"""Funciones de los Modelos a Mejorar:"""

#@title Regresion Logistica
# Funciones específicas para cada modelo
def run_logistic_regression(X_train, X_test, y_train, y_test):
    model = LogisticRegression(max_iter=2000)
    return train_and_evaluate(model, "Logistic Regression", X_train, X_test, y_train, y_test)

"""**Resultados Valores Predeterminados:** \
Modelo: Logistic Regression \
Precisión: 0.8950 \
Precisión (Precision): 0.8959 \
Exhaustividad (Recall): 0.8950 \
F1 Score: 0.8952 \
Tiempo de entrenamiento: 3.1934 segundos \
Uso de memoria durante el entrenamiento: 6.80 MiB \
Uso de CPU durante el entrenamiento: 6.50 %

"""

#@title Random Forest
def run_random_forest(X_train, X_test, y_train, y_test):
    model = RandomForestClassifier(n_estimators=100)
    return train_and_evaluate(model, "Random Forest", X_train, X_test, y_train, y_test)

"""**Resultados Valores Predeterminados:** \
Modelo: Random Forest \
Precisión: 0.9987 \
Precisión (Precision): 0.9987 \
Exhaustividad (Recall): 0.9987 \
F1 Score: 0.9987 \
Tiempo de entrenamiento: 8.0363 segundos \
Uso de memoria durante el entrenamiento: 11.25 MiB \
Uso de CPU durante el entrenamiento: -34.00 %

"""

#@title Gradiente

def run_gradient_boosting(X_train, X_test, y_train, y_test):
    model = GradientBoostingClassifier()
    return train_and_evaluate(model, "Gradient Boosting", X_train, X_test, y_train, y_test)

"""**Resultados Valores Predeterminados:** \
Modelo: Gradient Boosting \
Precisión: 0.9910 \
Precisión (Precision): 0.9911 \
Exhaustividad (Recall): 0.9910 \
F1 Score: 0.9910 \
Tiempo de entrenamiento: 19.1186 segundos \
Uso de memoria durante el entrenamiento: 9.10 MiB \
Uso de CPU durante el entrenamiento: -91.00 % \
"""

#@title Super Vector Machine

def run_svc(X_train, X_test, y_train, y_test):
    model = SVC()
    return train_and_evaluate(model, "Support Vector Classifier", X_train, X_test, y_train, y_test)

"""**Resultados Valores Predeterminados:** \
Modelo: Support Vector Classifier \
Precisión: 0.9773 \
Precisión (Precision): 0.9784 \
Exhaustividad (Recall): 0.9773 \
F1 Score: 0.9774 \
Tiempo de entrenamiento: 7.9673 segundos \
Uso de memoria durante el entrenamiento: 6.80 MiB \
Uso de CPU durante el entrenamiento: -34.00 %
"""

#@title K-Nearest Neighbors

def run_knn(X_train, X_test, y_train, y_test):
    model = KNeighborsClassifier()
    return train_and_evaluate(model, "K-Nearest Neighbors", X_train, X_test, y_train, y_test)

"""**Resultados Valores Predeterminados:** \
Modelo: K-Nearest Neighbors \
Precisión: 0.9930 \
Precisión (Precision): 0.9931 \
Exhaustividad (Recall): 0.9930 \
F1 Score: 0.9930 \
Tiempo de entrenamiento: 2.0560 segundos \
Uso de memoria durante el entrenamiento: 4.46 MiB \
Uso de CPU durante el entrenamiento: 6.50 %
"""

#@title Resultados

# Main
if __name__ == "__main__":
    # Cargar y preprocesar datos
    file_path = 'balanced_fetal_health.csv'
    X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path)

    # Ejecutar cada modelo
    results = []
    results.append(run_logistic_regression(X_train, X_test, y_train, y_test))
    results.append(run_random_forest(X_train, X_test, y_train, y_test))
    results.append(run_gradient_boosting(X_train, X_test, y_train, y_test))
    results.append(run_svc(X_train, X_test, y_train, y_test))
    results.append(run_knn(X_train, X_test, y_train, y_test))

    # Imprimir resultados
    for result in results:
        print(f"\nModelo: {result['model']}\n"
              f"Precisión: {result['accuracy']:.4f}\n"
              f"Precisión (Precision): {result['precision']:.4f}\n"
              f"Exhaustividad (Recall): {result['recall']:.4f}\n"
              f"F1 Score: {result['f1_score']:.4f}\n"
              f"Tiempo de entrenamiento: {result['train_time']:.4f} segundos\n"
              f"Uso de memoria: {result['memory_usage']:.2f} MiB\n"
              f"{'-' * 40}")